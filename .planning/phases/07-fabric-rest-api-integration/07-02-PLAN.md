---
phase: 07-fabric-rest-api-integration
plan: 02
type: tdd
wave: 2
depends_on: ["07-01"]
files_modified:
  - src/semantic_model_generator/fabric/__init__.py
  - src/semantic_model_generator/fabric/deployment.py
  - src/semantic_model_generator/fabric/polling.py
  - tests/fabric/test_deployment.py
  - tests/fabric/test_polling.py
autonomous: true

must_haves:
  truths:
    - "Semantic model can be created via Fabric REST API POST and returns model ID or operation ID"
    - "Existing semantic model definition can be updated via POST to updateDefinition endpoint"
    - "Long-running operations are polled with exponential backoff until Succeeded or Failed"
    - "Failed operations raise RuntimeError with error details from API response"
    - "Existing semantic model can be found by name within a workspace"
    - "Dev mode creates new model with UTC timestamp suffix appended to name"
    - "Prod mode overwrites existing model only when confirm_overwrite=True"
    - "Prod mode raises ValueError when model exists and confirm_overwrite=False"
  artifacts:
    - path: "src/semantic_model_generator/fabric/deployment.py"
      provides: "Create, update, find semantic models; dev/prod deploy orchestrators"
      exports: ["create_semantic_model", "update_semantic_model_definition", "find_semantic_model_by_name", "deploy_semantic_model_dev", "deploy_semantic_model_prod"]
    - path: "src/semantic_model_generator/fabric/polling.py"
      provides: "LRO polling with exponential backoff"
      exports: ["poll_operation", "get_operation_result"]
    - path: "tests/fabric/test_deployment.py"
      provides: "Deployment module tests"
    - path: "tests/fabric/test_polling.py"
      provides: "Polling module tests"
  key_links:
    - from: "src/semantic_model_generator/fabric/deployment.py"
      to: "src/semantic_model_generator/fabric/resolution.py"
      via: "resolve_workspace_id for name-to-GUID"
      pattern: "resolve_workspace_id|resolve_lakehouse_id"
    - from: "src/semantic_model_generator/fabric/deployment.py"
      to: "src/semantic_model_generator/fabric/packaging.py"
      via: "package_tmdl_for_fabric for payload assembly"
      pattern: "package_tmdl_for_fabric"
    - from: "src/semantic_model_generator/fabric/deployment.py"
      to: "src/semantic_model_generator/fabric/auth.py"
      via: "get_fabric_token for bearer token"
      pattern: "get_fabric_token"
    - from: "src/semantic_model_generator/fabric/deployment.py"
      to: "src/semantic_model_generator/fabric/polling.py"
      via: "poll_operation for LRO handling"
      pattern: "poll_operation|get_operation_result"
    - from: "src/semantic_model_generator/fabric/polling.py"
      to: "tenacity"
      via: "retry decorator with exponential backoff"
      pattern: "@retry|wait_exponential"
---

<objective>
Implement deployment and LRO polling for Fabric semantic models: create/update via REST API, long-running operation polling with exponential backoff, find-by-name lookup, and dev/prod deployment orchestrators with naming aligned to Phase 6 patterns.

Purpose: This completes the Fabric REST API integration. After this plan, the library can deploy semantic models to Fabric programmatically in both dev mode (timestamped, safe iteration) and prod mode (overwrite with explicit confirmation).

Output: Two source modules (deployment.py, polling.py), two test files, updated `__init__.py` exports.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-fabric-rest-api-integration/07-RESEARCH.md
@.planning/phases/07-fabric-rest-api-integration/07-01-SUMMARY.md

@src/semantic_model_generator/fabric/auth.py
@src/semantic_model_generator/fabric/resolution.py
@src/semantic_model_generator/fabric/packaging.py
@src/semantic_model_generator/output/writer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RED - Write failing tests for deployment and polling</name>
  <files>
    src/semantic_model_generator/fabric/deployment.py
    src/semantic_model_generator/fabric/polling.py
    src/semantic_model_generator/fabric/__init__.py
    tests/fabric/test_deployment.py
    tests/fabric/test_polling.py
  </files>
  <action>
    **Step 1: Create stub `fabric/polling.py`:**
    ```python
    def poll_operation(operation_id: str, token: str) -> dict:
        raise NotImplementedError

    def get_operation_result(operation_id: str, token: str) -> dict:
        raise NotImplementedError
    ```

    **Step 2: Create stub `fabric/deployment.py`:**
    ```python
    def find_semantic_model_by_name(workspace_id: str, model_name: str, token: str) -> str | None:
        raise NotImplementedError

    def create_semantic_model(workspace_id: str, display_name: str, definition: dict, token: str) -> tuple[str | None, str | None]:
        raise NotImplementedError

    def update_semantic_model_definition(workspace_id: str, semantic_model_id: str, definition: dict, token: str) -> str | None:
        raise NotImplementedError

    def deploy_semantic_model_dev(tmdl_files: dict[str, str], workspace: str, model_name: str) -> str:
        raise NotImplementedError

    def deploy_semantic_model_prod(tmdl_files: dict[str, str], workspace: str, model_name: str, confirm_overwrite: bool = False) -> str:
        raise NotImplementedError
    ```

    **Step 3: Update `fabric/__init__.py`** to add new exports:
    - From deployment: `find_semantic_model_by_name`, `create_semantic_model`, `update_semantic_model_definition`, `deploy_semantic_model_dev`, `deploy_semantic_model_prod`
    - From polling: `poll_operation`, `get_operation_result`

    **Step 4: Write `tests/fabric/test_polling.py`** (all tests mock `requests.get` or the internal `_call_fabric_api` from resolution):

    `poll_operation` tests:
    - `test_poll_operation_succeeds_immediately`: Mock API returns `{"status": "Succeeded"}` on first call. Verify returns operation dict with status "Succeeded".
    - `test_poll_operation_polls_until_success`: Mock returns "Running" twice, then "Succeeded". Verify 3 calls made, final result is "Succeeded".
    - `test_poll_operation_raises_on_failure`: Mock returns `{"status": "Failed", "error": {"errorCode": "TestError", "message": "Something failed"}}`. Verify `RuntimeError` raised with error details.
    - `test_poll_operation_uses_correct_endpoint`: Verify GET request to `operations/{operation_id}`.
    - `test_poll_operation_uses_bearer_token`: Verify Authorization header.

    `get_operation_result` tests:
    - `test_get_operation_result_returns_json`: Mock returns `{"id": "model-123"}`. Verify returns that dict.
    - `test_get_operation_result_uses_correct_endpoint`: Verify GET to `operations/{operation_id}/result`.

    **Step 5: Write `tests/fabric/test_deployment.py`** (all tests mock API calls and auth):

    `find_semantic_model_by_name` tests:
    - `test_find_existing_model`: Mock list API returns model with matching name. Returns model ID.
    - `test_find_nonexistent_model`: Mock returns no matches. Returns None.
    - `test_find_model_uses_correct_endpoint`: Verify GET to `workspaces/{ws_id}/semanticModels`.

    `create_semantic_model` tests:
    - `test_create_returns_id_on_201`: Mock POST returns 201 with `{"id": "model-123"}`. Verify returns `("model-123", None)`.
    - `test_create_returns_operation_id_on_202`: Mock POST returns 202 with `x-ms-operation-id` header. Verify returns `(None, "op-456")`.
    - `test_create_sends_correct_payload`: Verify POST body contains `displayName` and `definition`.
    - `test_create_uses_correct_endpoint`: Verify POST to `workspaces/{ws_id}/semanticModels`.

    `update_semantic_model_definition` tests:
    - `test_update_returns_none_on_200`: Mock returns 200. Verify returns None.
    - `test_update_returns_operation_id_on_202`: Mock returns 202 with operation ID header.
    - `test_update_uses_correct_endpoint`: Verify POST to `workspaces/{ws_id}/semanticModels/{model_id}/updateDefinition?updateMetadata=True`.
    - `test_update_sends_definition_payload`: Verify POST body.

    `deploy_semantic_model_dev` tests (mock auth + resolution + packaging + create + polling):
    - `test_dev_deploy_creates_model_with_timestamp_name`: Verify display name has UTC timestamp suffix (format `ModelName_YYYYMMDDTHHMMSSz`).
    - `test_dev_deploy_resolves_workspace_name`: Verify workspace name resolved via API.
    - `test_dev_deploy_returns_model_id_on_201`: Mock immediate creation, returns model ID.
    - `test_dev_deploy_polls_lro_on_202`: Mock 202 + polling + result, returns model ID from result.

    `deploy_semantic_model_prod` tests (mock auth + resolution + packaging + create/update + polling):
    - `test_prod_deploy_raises_without_confirmation`: Model exists, `confirm_overwrite=False` -> `ValueError`.
    - `test_prod_deploy_updates_existing_with_confirmation`: Model exists, `confirm_overwrite=True` -> calls update, returns existing ID.
    - `test_prod_deploy_creates_new_if_not_exists`: Model doesn't exist -> calls create, returns new ID.
    - `test_prod_deploy_uses_base_name`: Verify display name has NO timestamp suffix.
    - `test_prod_deploy_raises_clear_error_message`: Verify ValueError message includes model name and workspace info, mentions `confirm_overwrite=True`.

    **All tests must fail with NotImplementedError from stubs.**
  </action>
  <verify>
    `make test` shows all new tests failing with NotImplementedError. Existing tests (including 07-01 tests) still pass. `make lint` and `make typecheck` clean.
  </verify>
  <done>
    Stub modules exist with correct signatures. All new test files import successfully. Every new test fails with NotImplementedError. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: GREEN - Implement deployment and polling modules</name>
  <files>
    src/semantic_model_generator/fabric/deployment.py
    src/semantic_model_generator/fabric/polling.py
  </files>
  <action>
    **Implement `fabric/polling.py`:**

    Use `requests` for API calls and `tenacity` for retry logic.

    ```python
    import requests
    from tenacity import retry, retry_if_result, stop_after_attempt, wait_exponential

    FABRIC_API_BASE = "https://api.fabric.microsoft.com/v1"

    def _is_still_running(result: dict) -> bool:
        """Check if operation is still running (for tenacity retry)."""
        return result.get("status") == "Running"

    @retry(
        retry=retry_if_result(_is_still_running),
        stop=stop_after_attempt(60),
        wait=wait_exponential(multiplier=1, min=2, max=30),
    )
    def poll_operation(operation_id: str, token: str) -> dict:
        """Poll long-running operation until completion.

        Args:
            operation_id: Operation ID from x-ms-operation-id response header.
            token: Bearer token.

        Returns:
            Operation dict with "status" key ("Succeeded" or "Failed").

        Raises:
            RuntimeError: If operation status is "Failed", with error details.
        """
        headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
        response = requests.get(f"{FABRIC_API_BASE}/operations/{operation_id}", headers=headers)
        response.raise_for_status()

        operation = response.json()
        status = operation.get("status")

        if status == "Failed":
            error = operation.get("error", {})
            error_code = error.get("errorCode", "Unknown")
            error_msg = error.get("message", "No details")
            raise RuntimeError(f"Operation {operation_id} failed: [{error_code}] {error_msg}")

        return operation

    def get_operation_result(operation_id: str, token: str) -> dict:
        """Get result of a completed operation.

        Args:
            operation_id: Operation ID.
            token: Bearer token.

        Returns:
            Result dict (e.g., created semantic model object).
        """
        headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
        response = requests.get(f"{FABRIC_API_BASE}/operations/{operation_id}/result", headers=headers)
        response.raise_for_status()
        return response.json()
    ```

    Note: The `@retry` decorator with `retry_if_result` will keep polling while `_is_still_running` returns True. When status is "Succeeded", it returns the dict. When status is "Failed", the RuntimeError is raised (not retried, since it's an exception not a return value).

    **Implement `fabric/deployment.py`:**

    Import from sibling modules (auth, resolution, packaging, polling). Use `requests` for POST calls.

    `find_semantic_model_by_name(workspace_id, model_name, token) -> str | None`:
    - GET `workspaces/{workspace_id}/semanticModels`
    - Filter by `displayName == model_name`
    - Return `matches[0]["id"]` if found, else `None`
    - Use same headers/base URL pattern as polling

    `create_semantic_model(workspace_id, display_name, definition, token) -> tuple[str | None, str | None]`:
    - POST to `workspaces/{workspace_id}/semanticModels`
    - Body: `{"displayName": display_name, "definition": definition}`
    - If 201: return `(response.json()["id"], None)`
    - If 202: return `(None, response.headers.get("x-ms-operation-id"))`
    - Call `response.raise_for_status()` for other codes

    `update_semantic_model_definition(workspace_id, semantic_model_id, definition, token) -> str | None`:
    - POST to `workspaces/{workspace_id}/semanticModels/{semantic_model_id}/updateDefinition?updateMetadata=True`
    - Body: `{"definition": definition}`
    - If 200: return None
    - If 202: return operation ID from header

    `deploy_semantic_model_dev(tmdl_files, workspace, model_name) -> str`:
    1. `token = get_fabric_token()`
    2. Resolve workspace: `is_guid(workspace) ? workspace : resolve_workspace_id(workspace, token)`
    3. Generate timestamp name: `f"{model_name}_{datetime.now(UTC).strftime('%Y%m%dT%H%M%SZ')}"`  (import from `datetime import UTC, datetime`)
    4. Package: `definition = package_tmdl_for_fabric(tmdl_files)`
    5. Create: `model_id, op_id = create_semantic_model(workspace_id, deployment_name, definition, token)`
    6. If op_id: `poll_operation(op_id, token)` then `result = get_operation_result(op_id, token)` then `model_id = result["id"]`
    7. Return model_id (assert not None)

    `deploy_semantic_model_prod(tmdl_files, workspace, model_name, confirm_overwrite=False) -> str`:
    1. `token = get_fabric_token()`
    2. Resolve workspace
    3. `existing_id = find_semantic_model_by_name(workspace_id, model_name, token)`
    4. If existing_id and not confirm_overwrite: raise `ValueError(f"Semantic model '{model_name}' already exists. Pass confirm_overwrite=True to overwrite.")`
    5. Package: `definition = package_tmdl_for_fabric(tmdl_files)`
    6. If existing_id: call `update_semantic_model_definition(workspace_id, existing_id, definition, token)`, poll if op_id returned, return existing_id
    7. Else: call `create_semantic_model(workspace_id, model_name, definition, token)`, handle LRO, return model_id

    Run `make check` to verify all tests pass.
  </action>
  <verify>
    `make check` passes: all tests pass (deployment + polling + plan 01 tests + existing 299), ruff clean, mypy clean. `pytest tests/fabric/ -v` shows all fabric tests passing.
  </verify>
  <done>
    Deployment and polling fully implemented. Create returns model ID on 201, operation ID on 202. Update handles 200/202. Polling uses tenacity exponential backoff. Dev mode appends UTC timestamp. Prod mode requires confirm_overwrite=True for existing models. All quality gates pass.
  </done>
</task>

</tasks>

<verification>
1. `make check` passes (lint + typecheck + all tests)
2. `pytest tests/fabric/ -v` shows ALL fabric tests passing (auth + resolution + packaging + deployment + polling)
3. `python -c "from semantic_model_generator.fabric import deploy_semantic_model_dev, deploy_semantic_model_prod, poll_operation, get_operation_result, find_semantic_model_by_name, create_semantic_model, update_semantic_model_definition; print('All exports OK')"` succeeds
4. Verify dev mode naming produces timestamp suffix format aligned with Phase 6 pattern (`YYYYMMDDTHHMMSSz`)
5. Verify prod mode raises ValueError when model exists without confirm_overwrite
</verification>

<success_criteria>
- Semantic model creation handles both 201 (immediate) and 202 (LRO) responses
- Semantic model update handles both 200 (immediate) and 202 (LRO) responses
- LRO polling uses tenacity with exponential backoff (min=2s, max=30s, max 60 attempts)
- Failed operations raise RuntimeError with error code and message
- Dev mode appends UTC timestamp to model name (format aligned with Phase 6)
- Prod mode requires explicit confirm_overwrite=True for existing models
- Prod mode raises ValueError with clear message including model name
- Find-by-name returns None for nonexistent models, model ID for existing ones
- All functions have correct type annotations and docstrings
- `make check` clean (lint + typecheck + tests)
</success_criteria>

<output>
After completion, create `.planning/phases/07-fabric-rest-api-integration/07-02-SUMMARY.md`
</output>
