---
phase: 08-pipeline-orchestration-public-api
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/semantic_model_generator/pipeline.py
  - tests/test_pipeline.py
autonomous: true

must_haves:
  truths:
    - "PipelineConfig validates all required parameters at construction time and rejects invalid configurations"
    - "PipelineError identifies the failing pipeline stage and preserves the original exception traceback"
    - "generate_semantic_model() orchestrates connect, discover, filter, classify, infer, generate, and output stages in sequence"
    - "Folder output mode writes TMDL structure to disk via write_tmdl_folder"
    - "Fabric output mode deploys via deploy_semantic_model_dev or deploy_semantic_model_prod"
    - "Each pipeline stage failure produces a PipelineError with stage name and cause"
  artifacts:
    - path: "src/semantic_model_generator/pipeline.py"
      provides: "PipelineConfig, PipelineError, generate_semantic_model"
      contains: "def generate_semantic_model"
    - path: "tests/test_pipeline.py"
      provides: "Unit tests for pipeline module"
      contains: "class TestPipelineConfig"
  key_links:
    - from: "src/semantic_model_generator/pipeline.py"
      to: "semantic_model_generator.schema"
      via: "imports create_fabric_connection, discover_tables, filter_tables, classify_tables, infer_relationships"
      pattern: "from semantic_model_generator\\.schema import"
    - from: "src/semantic_model_generator/pipeline.py"
      to: "semantic_model_generator.tmdl"
      via: "imports generate_all_tmdl"
      pattern: "from semantic_model_generator\\.tmdl import"
    - from: "src/semantic_model_generator/pipeline.py"
      to: "semantic_model_generator.output"
      via: "imports write_tmdl_folder"
      pattern: "from semantic_model_generator\\.output import"
    - from: "src/semantic_model_generator/pipeline.py"
      to: "semantic_model_generator.fabric"
      via: "imports deploy_semantic_model_dev, deploy_semantic_model_prod"
      pattern: "from semantic_model_generator\\.fabric import"
---

<objective>
Create the pipeline orchestration module with PipelineConfig, PipelineError, and generate_semantic_model() function using TDD.

Purpose: This is the core public API of the library. A single function call orchestrates the entire semantic model generation pipeline from database connection through TMDL output. Configuration is validated up front via frozen dataclass, and every pipeline stage wraps errors with stage identification for actionable debugging.

Output: Working pipeline.py module with comprehensive unit tests covering config validation, error wrapping, and both output modes.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-pipeline-orchestration-public-api/08-RESEARCH.md

@src/semantic_model_generator/schema/__init__.py
@src/semantic_model_generator/schema/connection.py
@src/semantic_model_generator/schema/discovery.py
@src/semantic_model_generator/schema/filtering.py
@src/semantic_model_generator/schema/classification.py
@src/semantic_model_generator/schema/relationships.py
@src/semantic_model_generator/tmdl/__init__.py
@src/semantic_model_generator/tmdl/generate.py
@src/semantic_model_generator/output/__init__.py
@src/semantic_model_generator/output/writer.py
@src/semantic_model_generator/fabric/__init__.py
@src/semantic_model_generator/fabric/deployment.py
@src/semantic_model_generator/fabric/resolution.py
@src/semantic_model_generator/domain/types.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RED - Write failing tests for pipeline module</name>
  <files>src/semantic_model_generator/pipeline.py, tests/test_pipeline.py</files>
  <action>
Create stub `src/semantic_model_generator/pipeline.py` with:

1. **PipelineError(Exception)** with attributes `stage: str`, `message: str`, `cause: Exception | None`. The `__init__` calls `super().__init__(f"[{stage}] {message}")`. Stub raises NotImplementedError.

2. **PipelineConfig frozen dataclass** (`frozen=True, slots=True, kw_only=True`) with these fields:
   - `sql_endpoint: str` - Fabric SQL analytics endpoint
   - `database: str` - Database name
   - `schemas: tuple[str, ...]` - Schema names (no defaults, user must specify)
   - `key_prefixes: tuple[str, ...]` - Key column prefixes (no defaults, user must specify)
   - `model_name: str` - Semantic model name
   - `catalog_name: str` - Fabric catalog name for DirectLake expression
   - `include_tables: tuple[str, ...] | None = None` - Optional include filter
   - `exclude_tables: tuple[str, ...] | None = None` - Optional exclude filter
   - `output_mode: str = "folder"` - Either "folder" or "fabric"
   - `output_path: Path | None = None` - Required for folder mode
   - `workspace: str | None = None` - Required for fabric mode (name or GUID)
   - `lakehouse_or_warehouse: str | None = None` - Required for fabric mode (name or GUID)
   - `item_type: str = "Lakehouse"` - Either "Lakehouse" or "Warehouse"
   - `dev_mode: bool = True` - Default safe iteration
   - `overwrite: bool = False` - Prod folder mode protection
   - `confirm_overwrite: bool = False` - Prod Fabric mode protection
   - `__post_init__` stub that raises NotImplementedError

3. **generate_semantic_model(config: PipelineConfig) -> dict[str, Any]** stub that raises NotImplementedError.

Create `tests/test_pipeline.py` with these test classes and tests:

**TestPipelineConfig** (~12 tests):
- `test_valid_folder_config` - Constructs valid folder mode config, asserts all fields set correctly
- `test_valid_fabric_config` - Constructs valid fabric mode config, asserts all fields set correctly
- `test_schemas_cannot_be_empty` - Empty schemas tuple raises ValueError with "schemas" in message
- `test_key_prefixes_cannot_be_empty` - Empty key_prefixes tuple raises ValueError with "key_prefixes" in message
- `test_invalid_output_mode` - output_mode="invalid" raises ValueError with "output_mode" in message
- `test_folder_mode_requires_output_path` - output_mode="folder" without output_path raises ValueError
- `test_fabric_mode_requires_workspace` - output_mode="fabric" without workspace raises ValueError
- `test_fabric_mode_requires_lakehouse` - output_mode="fabric" without lakehouse_or_warehouse raises ValueError
- `test_config_is_frozen` - Attempting to set attribute on constructed config raises FrozenInstanceError
- `test_config_defaults` - Verify default values: output_mode="folder", dev_mode=True, overwrite=False, confirm_overwrite=False, item_type="Lakehouse"
- `test_include_exclude_default_none` - include_tables and exclude_tables default to None
- `test_invalid_item_type` - item_type="Invalid" raises ValueError

**TestPipelineError** (4 tests):
- `test_error_contains_stage` - PipelineError("connection", "msg") has stage="connection" and "[connection]" in str
- `test_error_contains_message` - Message appears in str representation
- `test_error_preserves_cause` - cause attribute stores original exception
- `test_error_without_cause` - cause defaults to None

**TestGenerateSemanticModelFolderMode** (~6 tests):
Mock ALL external dependencies using `unittest.mock.patch`:
- Patch `semantic_model_generator.pipeline.create_fabric_connection` (NOT the schema module)
- Patch `semantic_model_generator.pipeline.discover_tables`
- Patch `semantic_model_generator.pipeline.filter_tables`
- Patch `semantic_model_generator.pipeline.classify_tables`
- Patch `semantic_model_generator.pipeline.infer_relationships`
- Patch `semantic_model_generator.pipeline.generate_all_tmdl`
- Patch `semantic_model_generator.pipeline.write_tmdl_folder`

Tests:
- `test_folder_mode_calls_all_stages` - Verify all 7 functions are called in the correct order with correct arguments
- `test_folder_mode_returns_result` - Returns dict with mode="folder", output_path, and summary keys
- `test_folder_mode_passes_dev_mode` - dev_mode and overwrite passed through to write_tmdl_folder
- `test_folder_mode_passes_include_exclude` - include_tables and exclude_tables forwarded to filter_tables
- `test_connection_error_wraps_as_pipeline_error` - Connection failure raises PipelineError with stage="connection"
- `test_discovery_error_wraps_as_pipeline_error` - Discovery failure raises PipelineError with stage="discovery"

**TestGenerateSemanticModelFabricMode** (~4 tests):
Mock same dependencies plus fabric deployment functions:
- Patch `semantic_model_generator.pipeline.deploy_semantic_model_dev`
- Patch `semantic_model_generator.pipeline.deploy_semantic_model_prod`

Tests:
- `test_fabric_dev_mode_calls_deploy_dev` - dev_mode=True calls deploy_semantic_model_dev with correct args
- `test_fabric_prod_mode_calls_deploy_prod` - dev_mode=False calls deploy_semantic_model_prod with correct args
- `test_fabric_mode_returns_result` - Returns dict with mode="fabric", model_id, and model_name keys
- `test_deployment_error_wraps_as_pipeline_error` - Deployment failure raises PipelineError with stage="deployment"

**TestPipelineErrorStages** (~4 tests, one per remaining stage):
- `test_filtering_error_wraps` - filter_tables failure -> PipelineError stage="filtering"
- `test_classification_error_wraps` - classify_tables failure -> PipelineError stage="classification"
- `test_relationship_error_wraps` - infer_relationships failure -> PipelineError stage="relationships"
- `test_tmdl_generation_error_wraps` - generate_all_tmdl failure -> PipelineError stage="tmdl_generation"

All tests should fail with NotImplementedError from the stubs.

Commit message: `test(08-01): add failing tests for pipeline config, error handling, and orchestration`
  </action>
  <verify>
Run `python -m pytest tests/test_pipeline.py -v` - all new tests MUST fail with NotImplementedError. Run `python -m pytest --ignore=tests/test_pipeline.py -q` - all 354 existing tests MUST still pass. Run `make lint` and `make typecheck` - both MUST pass.
  </verify>
  <done>
All new pipeline tests fail with NotImplementedError. All 354 existing tests pass. Lint and typecheck clean.
  </done>
</task>

<task type="auto">
  <name>Task 2: GREEN - Implement pipeline module</name>
  <files>src/semantic_model_generator/pipeline.py</files>
  <action>
Implement all stubs in `src/semantic_model_generator/pipeline.py`:

1. **PipelineError** - Already correct in stub (simple Exception subclass with stage, message, cause attributes).

2. **PipelineConfig.__post_init__** validation:
   - `schemas` cannot be empty tuple -> ValueError("schemas cannot be empty; at least one schema required")
   - `key_prefixes` cannot be empty tuple -> ValueError("key_prefixes cannot be empty; provide prefixes like ('SK_', 'ID_')")
   - `output_mode` must be "folder" or "fabric" -> ValueError(f"output_mode must be 'folder' or 'fabric', got {self.output_mode}")
   - `item_type` must be "Lakehouse" or "Warehouse" -> ValueError(f"item_type must be 'Lakehouse' or 'Warehouse', got {self.item_type}")
   - If output_mode="folder" and output_path is None -> ValueError("output_path required when output_mode='folder'")
   - If output_mode="fabric" and workspace is None -> ValueError("workspace required when output_mode='fabric'")
   - If output_mode="fabric" and lakehouse_or_warehouse is None -> ValueError("lakehouse_or_warehouse required when output_mode='fabric'")

3. **generate_semantic_model** implementation:
   Import at top of module:
   ```python
   from semantic_model_generator.schema import (
       create_fabric_connection, discover_tables, filter_tables,
       classify_tables, infer_relationships,
   )
   from semantic_model_generator.tmdl import generate_all_tmdl
   from semantic_model_generator.output import write_tmdl_folder
   from semantic_model_generator.fabric import deploy_semantic_model_dev, deploy_semantic_model_prod
   ```

   Pipeline stages with try/except wrapping:

   **Stage 1: Connection**
   ```python
   try:
       conn = create_fabric_connection(config.sql_endpoint, config.database)
   except Exception as e:
       raise PipelineError("connection", f"Failed to connect to {config.sql_endpoint}: {e}", e) from e
   ```

   **Stage 2: Discovery**
   ```python
   try:
       tables = discover_tables(conn, config.schemas)
   except Exception as e:
       raise PipelineError("discovery", f"Failed to read schema for {config.schemas}: {e}", e) from e
   ```

   **Stage 3: Filtering**
   ```python
   try:
       filtered = filter_tables(tables, config.include_tables, config.exclude_tables)
   except Exception as e:
       raise PipelineError("filtering", f"Failed to filter tables: {e}", e) from e
   ```

   **Stage 4: Classification**
   ```python
   try:
       classifications = classify_tables(filtered, config.key_prefixes)
   except Exception as e:
       raise PipelineError("classification", f"Failed to classify tables: {e}", e) from e
   ```

   **Stage 5: Relationship inference**
   ```python
   try:
       relationships = infer_relationships(filtered, classifications, config.key_prefixes)
   except Exception as e:
       raise PipelineError("relationships", f"Failed to infer relationships: {e}", e) from e
   ```

   **Stage 6: TMDL generation**
   ```python
   try:
       tmdl_files = generate_all_tmdl(
           config.model_name, filtered, classifications, relationships,
           config.key_prefixes, config.catalog_name,
       )
   except Exception as e:
       raise PipelineError("tmdl_generation", f"Failed to generate TMDL: {e}", e) from e
   ```

   **Stage 7: Output** - branch on output_mode:

   For folder mode:
   ```python
   try:
       summary = write_tmdl_folder(
           tmdl_files, config.output_path, config.model_name,
           config.dev_mode, config.overwrite,
       )
       return {"mode": "folder", "output_path": summary.output_path, "summary": summary}
   except Exception as e:
       raise PipelineError("output", f"Failed to write folder at {config.output_path}: {e}", e) from e
   ```

   For fabric mode:
   ```python
   try:
       if config.dev_mode:
           model_id = deploy_semantic_model_dev(tmdl_files, config.workspace, config.model_name)
       else:
           model_id = deploy_semantic_model_prod(
               tmdl_files, config.workspace, config.model_name, config.confirm_overwrite,
           )
       return {"mode": "fabric", "model_id": model_id, "model_name": config.model_name}
   except Exception as e:
       raise PipelineError("deployment", f"Failed to deploy to workspace {config.workspace}: {e}", e) from e
   ```

   IMPORTANT: The `config.output_path` type is `Path | None`. When passing to `write_tmdl_folder`, it's guaranteed non-None due to `__post_init__` validation. Use `assert config.output_path is not None` before the call to satisfy mypy, or cast. Similarly `assert config.workspace is not None` for fabric mode.

   Commit message: `feat(08-01): implement pipeline config, error handling, and orchestration`
  </action>
  <verify>
Run `python -m pytest tests/test_pipeline.py -v` - all new tests MUST pass. Run `python -m pytest -q` - all tests (354 + new) MUST pass. Run `make check` - lint + typecheck + test all clean.
  </verify>
  <done>
All pipeline tests pass. All existing tests still pass. PipelineConfig validates all parameters, generate_semantic_model orchestrates all stages with error wrapping, and both folder and fabric output modes work. make check clean.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_pipeline.py -v` - all tests pass
2. `python -m pytest -q` - all tests pass (354 existing + ~30 new)
3. `make check` - lint + typecheck + test all clean
4. `python -c "from semantic_model_generator.pipeline import PipelineConfig, PipelineError, generate_semantic_model"` - imports work
5. PipelineConfig rejects invalid configurations with clear error messages
6. generate_semantic_model wraps all stage errors in PipelineError with stage identification
</verification>

<success_criteria>
- PipelineConfig frozen dataclass validates all configuration parameters at construction time
- PipelineError exception class identifies pipeline stage and preserves original exception
- generate_semantic_model() calls all phases in sequence: connect -> discover -> filter -> classify -> infer -> generate -> output
- Folder output mode calls write_tmdl_folder with correct parameters
- Fabric output mode calls deploy_semantic_model_dev or deploy_semantic_model_prod based on dev_mode flag
- Every pipeline stage failure is caught and re-raised as PipelineError with stage name
- All tests pass, make check clean
</success_criteria>

<output>
After completion, create `.planning/phases/08-pipeline-orchestration-public-api/08-01-SUMMARY.md`
</output>
