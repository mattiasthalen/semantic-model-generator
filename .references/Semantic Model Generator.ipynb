{"cells":[{"cell_type":"markdown","source":["# Semantic Model Generator"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"bba18637-08a5-4d33-a196-cddd97a79cba"},{"cell_type":"markdown","source":["## Requirements"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"7a1e8eb9-5c21-4ede-86a4-1e87fbfb9922"},{"cell_type":"code","source":["!pip install -q uv\n","!uv pip install -q mssql-python --system"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:19.2199032Z","session_start_time":"2026-02-06T10:59:19.2206986Z","execution_start_time":"2026-02-06T10:59:22.9446387Z","execution_finish_time":"2026-02-06T10:59:33.719497Z","parent_msg_id":"48decb93-e334-4493-b958-759397fca344"}},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"b9d1c24f-a743-4af2-a1b2-36d8226c2119"},{"cell_type":"code","source":["import mssql_python\n","import pandas as pd\n","import struct\n","import os\n","import sys\n","import uuid\n","import hashlib\n","import base64\n","import json\n","import time\n","import requests\n","import contextlib\n","import io\n","\n","from pathlib import Path\n","from typing import Dict, List, Tuple, Optional, Any, Union"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:19.514726Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:33.7206256Z","execution_finish_time":"2026-02-06T10:59:39.4352848Z","parent_msg_id":"44a32575-af13-4413-8e05-5c316c4dada7"}},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"aa1dcff8-30cf-4480-b8d6-91813ee8fd2d"},{"cell_type":"markdown","source":["## Helper Functions"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"28fcdfb8-fbd7-4cf9-870b-14a467383008"},{"cell_type":"code","source":["def connect_to_warehouse(sql_endpoint: str, database: str):\n","    \"\"\"Connect to Fabric warehouse and return a cursor.\"\"\"\n","    token_bytes = notebookutils.credentials.getToken(\"https://database.windows.net\").encode(\"UTF-16-LE\")\n","\n","    conn_str = (\n","        f\"Server={sql_endpoint},1433;\"\n","        f\"Database={database};\"\n","        \"Encrypt=yes;\"\n","        \"TrustServerCertificate=no;\"\n","    )\n","\n","    token_struct = struct.pack(\n","        f\"<I{len(token_bytes)}s\",\n","        len(token_bytes),\n","        token_bytes\n","    )\n","\n","    conn = mssql_python.connect(conn_str, attrs_before={1256: token_struct})\n","    return conn.cursor()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:19.923667Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:39.4363996Z","execution_finish_time":"2026-02-06T10:59:39.7708319Z","parent_msg_id":"26bc12ac-2e38-4826-876e-59fa4a00f6ce"}},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"f116d7b7"},{"cell_type":"code","source":["def load_information_schema(cursor, schemas=(\"Dim\", \"Fact\")) -> pd.DataFrame:\n","    \"\"\"Load INFORMATION_SCHEMA.COLUMNS into a DataFrame.\"\"\"\n","    if isinstance(schemas, str):\n","        schemas = [schemas]\n","\n","    schema_list = \", \".join([f\"'{s}'\" for s in schemas])\n","\n","    sql = f\"\"\"\n","    SELECT\n","        [TABLE_CATALOG],\n","        [TABLE_SCHEMA],\n","        [TABLE_NAME],\n","        [COLUMN_NAME],\n","        [DATA_TYPE],\n","        [IS_NULLABLE],\n","        [CHARACTER_MAXIMUM_LENGTH],\n","        [NUMERIC_PRECISION],\n","        [NUMERIC_SCALE],\n","        [ORDINAL_POSITION]\n","    FROM [INFORMATION_SCHEMA].[COLUMNS]\n","    WHERE [TABLE_SCHEMA] IN ({schema_list})\n","    ORDER BY\n","        [TABLE_CATALOG],\n","        [TABLE_SCHEMA],\n","        [TABLE_NAME],\n","        [ORDINAL_POSITION];\n","    \"\"\"\n","\n","    cursor.execute(sql)\n","    rows = cursor.fetchall()\n","\n","    return pd.DataFrame.from_records(\n","        rows,\n","        columns=[c[0] for c in cursor.description]\n","    )\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:20.3280396Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:39.7720259Z","execution_finish_time":"2026-02-06T10:59:40.064325Z","parent_msg_id":"8863346e-e0ab-4ce8-a76c-b6a454fc3c89"}},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"57dba73d"},{"cell_type":"code","source":["def deterministic_uuid(namespace: str, *values: str) -> str:\n","    \"\"\"\n","    Generate a deterministic UUID based on namespace and values.\n","    \n","    Args:\n","        namespace: Namespace for the UUID (e.g., 'column', 'relationship', 'table')\n","        *values: Values to include in the hash (e.g., table name, column name)\n","    \n","    Returns:\n","        UUID string\n","        \n","    Examples:\n","        >>> uuid1 = deterministic_uuid('column', 'customers', 'id')\n","        >>> uuid2 = deterministic_uuid('column', 'customers', 'id')\n","        >>> uuid1 == uuid2\n","        True\n","        >>> uuid3 = deterministic_uuid('column', 'customers', 'name')\n","        >>> uuid1 != uuid3\n","        True\n","    \"\"\"\n","    # Create a stable string from namespace and values\n","    content = f\"{namespace}:{'|'.join(values)}\"\n","    # Generate MD5 hash and convert to UUID format\n","    hash_bytes = hashlib.md5(content.encode('utf-8')).digest()\n","    return str(uuid.UUID(bytes=hash_bytes))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:20.7227111Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:40.0654435Z","execution_finish_time":"2026-02-06T10:59:40.437069Z","parent_msg_id":"ff8d3bf7-905a-4ae1-9355-30a0bc2093bf"}},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"072e9ce5-1ddb-4ad4-b6f4-876a129aa2b5"},{"cell_type":"code","source":["def sql_type_to_tmdl_type(sql_type: str, column_name: str) -> Tuple[str, str]:\n","    \"\"\"\n","    Convert SQL data type to TMDL data type and format string.\n","    \n","    Args:\n","        sql_type: SQL data type (e.g., 'bigint', 'varchar', 'datetime')\n","        column_name: Column name (used for context)\n","    \n","    Returns:\n","        Tuple of (dataType, formatString)\n","        \n","    Examples:\n","        >>> sql_type_to_tmdl_type('bigint', 'count')\n","        ('int64', '0')\n","        >>> sql_type_to_tmdl_type('varchar', 'name')\n","        ('string', '')\n","        >>> sql_type_to_tmdl_type('datetime', 'created_at')\n","        ('dateTime', 'General Date')\n","        >>> sql_type_to_tmdl_type('decimal', 'amount')\n","        ('decimal', '0.00')\n","        >>> sql_type_to_tmdl_type('bit', 'is_active')\n","        ('boolean', '')\n","    \"\"\"\n","    sql_type_lower = sql_type.lower()\n","    \n","    # Date/Time types\n","    if sql_type_lower in ('datetime', 'datetime2', 'date', 'smalldatetime', 'timestamp', 'timestamptz', 'timestamp_tz'):\n","        return 'dateTime', 'General Date'\n","    elif sql_type_lower == 'time':\n","        return 'dateTime', 'Long Time'\n","    \n","    # Numeric types\n","    elif sql_type_lower in ('int', 'bigint', 'smallint', 'tinyint'):\n","        return 'int64', '0'\n","    elif sql_type_lower in ('decimal', 'numeric', 'money', 'smallmoney'):\n","        return 'decimal', '0.00'\n","    elif sql_type_lower in ('float', 'real'):\n","        return 'double', '0.00'\n","    \n","    # Boolean\n","    elif sql_type_lower == 'bit':\n","        return 'boolean', ''\n","    \n","    # String (default)\n","    else:\n","        return 'string', ''"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:21.2572614Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:40.438152Z","execution_finish_time":"2026-02-06T10:59:40.7750276Z","parent_msg_id":"d278f6af-ad9e-4044-9b3f-1a308e23a239"}},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"67a40d8f-41bf-4aaa-9c37-00b83c36b8da"},{"cell_type":"code","source":["def determine_summarization(column_name: str, data_type: str) -> str:\n","    \"\"\"\n","    Determine summarization strategy for a column.\n","    \n","    Args:\n","        column_name: Name of the column\n","        data_type: SQL data type\n","    \n","    Returns:\n","        Summarization strategy ('sum' or 'none')\n","        \n","    Examples:\n","        >>> determine_summarization('measure__amount', 'decimal')\n","        'sum'\n","        >>> determine_summarization('name', 'varchar')\n","        'none'\n","        >>> determine_summarization('quantity', 'int')\n","        'none'\n","        >>> determine_summarization('year', 'bigint')\n","        'none'\n","        >>> determine_summarization('id', 'int')\n","        'none'\n","    \"\"\"\n","    # Only summarize columns explicitly marked as measures\n","    if column_name.startswith('measure__'):\n","        return 'sum'\n","    \n","    # Everything else: no summarization (Power BI will handle aggregation in DAX)\n","    return 'none'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:21.7712047Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:40.7761708Z","execution_finish_time":"2026-02-06T10:59:41.0936231Z","parent_msg_id":"2ed92a7c-2462-4476-b193-37fed20b4ad3"}},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"1a6b85aa-8d7a-42d3-a4f1-c2288aeb28cc"},{"cell_type":"code","source":["def identify_relationships(\n","    tables_metadata: Dict[str, List[Dict[str, Any]]],\n","    key_prefixes: Union[str, List[str]] = None,\n","    exact_match_prefixes: Union[str, List[str]] = None\n",") -> Tuple[List[Dict[str, str]], List[str]]:\n","    \"\"\"\n","    Identify relationships for a star schema.\n","\n","    Automatically detects dimensions vs facts based on key column count:\n","    - Dimension: Tables with exactly 1 key column (their primary key only)\n","    - Fact: Tables with >1 key columns (their PK + foreign keys to dimensions)\n","\n","    Relationships are 1:* from dimension to fact.\n","\n","    Supports role-playing dimensions where the same dimension is referenced multiple times\n","    with different roles (e.g., _hk__customer__bill_to and _hk__customer__sell_to both\n","    connect to Dim Customer, or _wk__period__document and _wk__period__due both connect\n","    to Dim Period). The first relationship (by column order) is marked active,\n","    subsequent ones are inactive.\n","\n","    Columns matching exact_match_prefixes use exact matching only (no role-playing pattern).\n","\n","    Args:\n","        tables_metadata: Dictionary mapping table names to column metadata lists\n","        key_prefixes: Column prefix(es) to identify hash keys. Can be a string or list of strings (default: ['_hk__', '_wk__'])\n","        exact_match_prefixes: Column prefix(es) that should use exact matching only, not role-playing pattern. Can be a string or list of strings (default: ['_wk__ref__'])\n","\n","    Returns:\n","        Tuple of (list of relationship dictionaries, list of tables with no relationships)\n","\n","    Examples:\n","        >>> metadata = {\n","        ...     'dim__customers': [\n","        ...         {'COLUMN_NAME': '_hk__customer', 'DATA_TYPE': 'string'},\n","        ...         {'COLUMN_NAME': 'name', 'DATA_TYPE': 'string'}\n","        ...     ],\n","        ...     'fact__sales': [\n","        ...         {'COLUMN_NAME': '_hk__sale', 'DATA_TYPE': 'string'},\n","        ...         {'COLUMN_NAME': '_hk__customer', 'DATA_TYPE': 'string'},\n","        ...         {'COLUMN_NAME': 'amount', 'DATA_TYPE': 'decimal'}\n","        ...     ]\n","        ... }\n","        >>> rels, no_rels = identify_relationships(metadata)\n","        >>> len(rels)\n","        1\n","        >>> rels[0]['from_table']  # Fact is the 'from' (* side)\n","        'fact__sales'\n","        >>> rels[0]['to_table']  # Dimension is the 'to' (1 side)\n","        'dim__customers'\n","    \"\"\"\n","    if key_prefixes is None:\n","        key_prefixes = ['_hk__', '_wk__']\n","    elif isinstance(key_prefixes, str):\n","        key_prefixes = [key_prefixes]\n","\n","    if exact_match_prefixes is None:\n","        exact_match_prefixes = ['_wk__ref__']\n","    elif isinstance(exact_match_prefixes, str):\n","        exact_match_prefixes = [exact_match_prefixes]\n","\n","    relationships: List[Dict[str, str]] = []\n","    tables_with_relationships = set()\n","\n","    # Classify tables based on key column count\n","    dim_tables: Dict[str, str] = {}  # table_name -> primary key column\n","    fact_tables: Dict[str, List[Dict[str, Any]]] = {}  # table_name -> list of key column metadata (to preserve order)\n","\n","    for table_name, columns in tables_metadata.items():\n","        hk_cols = [\n","            col\n","            for col in columns\n","            if any(col['COLUMN_NAME'].startswith(prefix) for prefix in key_prefixes)\n","        ]\n","\n","        if len(hk_cols) == 1:\n","            # Dimension: exactly 1 key column (the PK)\n","            dim_tables[table_name] = hk_cols[0]['COLUMN_NAME']\n","        elif len(hk_cols) > 1:\n","            # Fact: multiple key columns (PK + FKs) - preserve column metadata with order\n","            fact_tables[table_name] = hk_cols\n","\n","    # Helper function to extract the base key name from a column\n","    # e.g., _hk__customer__bill_to -> _hk__customer\n","    # e.g., _hk__customer -> _hk__customer\n","    # e.g., _wk__period__document -> _wk__period\n","    # Exception: columns matching exact_match_prefixes use exact matching only (no role-playing)\n","    def extract_base_key(column_name: str, prefixes: List[str]) -> Optional[str]:\n","        \"\"\"Extract the base key name (prefix + first segment).\n","\n","        Returns None for columns that should use exact matching only.\n","        \"\"\"\n","        # Check if column matches any exact-match prefix\n","        for exact_prefix in exact_match_prefixes:\n","            if column_name.startswith(exact_prefix):\n","                return None\n","\n","        for prefix in prefixes:\n","            if column_name.startswith(prefix):\n","                # Remove prefix\n","                without_prefix = column_name[len(prefix):]\n","                # Get first segment (before the first __ if any)\n","                if '__' in without_prefix:\n","                    first_segment = without_prefix.split('__')[0]\n","                else:\n","                    first_segment = without_prefix\n","                # Reconstruct base key\n","                return f\"{prefix}{first_segment}\"\n","        return None\n","\n","    # Create relationships: fact (*) -> dimension (1)\n","    # In Power BI: fromColumn = many side, toColumn = one side\n","    for dim_name, dim_pk in dim_tables.items():\n","        # Track first relationship per fact-dimension pair (for setting isActive)\n","        dimension_base_key = extract_base_key(dim_pk, key_prefixes)\n","\n","        for fact_name, fact_key_cols in fact_tables.items():\n","            # Find all matching columns in the fact table\n","            # Match by exact name OR by base key name (when both support it)\n","            matching_cols = []\n","            for col_metadata in fact_key_cols:\n","                fact_col_name = col_metadata['COLUMN_NAME']\n","                fact_base_key = extract_base_key(fact_col_name, key_prefixes)\n","\n","                # Match if exact match OR if both have base keys and they match\n","                if fact_col_name == dim_pk or (fact_base_key is not None and dimension_base_key is not None and fact_base_key == dimension_base_key):\n","                    matching_cols.append((col_metadata, fact_col_name))\n","\n","            # Create relationships for all matches\n","            # First one (by column order) is active, rest are inactive\n","            for idx, (col_metadata, fact_col_name) in enumerate(matching_cols):\n","                is_active = (idx == 0)\n","\n","                # Use the fact column name in the relationship ID to make each one unique\n","                relationship_id = deterministic_uuid('relationship', fact_name, dim_name, fact_col_name, dim_pk)\n","                relationships.append({\n","                    'id': relationship_id,\n","                    'from_table': fact_name,     # Fact (* side)\n","                    'from_column': fact_col_name,\n","                    'to_table': dim_name,        # Dimension (1 side)\n","                    'to_column': dim_pk,\n","                    'is_active': is_active\n","                })\n","                tables_with_relationships.add(dim_name)\n","                tables_with_relationships.add(fact_name)\n","\n","    # Identify tables with no relationships\n","    all_tables = set(tables_metadata.keys())\n","    tables_without_relationships = sorted(all_tables - tables_with_relationships)\n","\n","    return relationships, tables_without_relationships"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:22.0533903Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:41.0948642Z","execution_finish_time":"2026-02-06T10:59:41.4172303Z","parent_msg_id":"7fc5bc8e-4977-49ef-83a5-182d6ff9e609"}},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"fd7a8b7e-c83c-4ed0-869f-613921feaf8f"},{"cell_type":"code","source":["def generate_column_tmdl(col: Dict[str, Any], table_name: str, schema: str) -> str:\n","    \"\"\"\n","    Generate TMDL content for a single column.\n","\n","    Args:\n","        col: Column metadata dictionary\n","        table_name: Name of the table\n","        schema: Schema name\n","\n","    Returns:\n","        TMDL string for the column\n","\n","    Examples:\n","        >>> col = {'COLUMN_NAME': 'id', 'DATA_TYPE': 'bigint'}\n","        >>> tmdl = generate_column_tmdl(col, 'customers', 'star_schema')\n","        >>> 'column id' in tmdl\n","        True\n","        >>> 'dataType: int64' in tmdl\n","        True\n","    \"\"\"\n","    col_name = col['COLUMN_NAME']\n","    sql_type = col['DATA_TYPE']\n","\n","    # Always quote column names for safety and consistency\n","    column_header = f\"\\tcolumn '{col_name}'\"\n","    lines = [column_header]\n","    \n","    # Determine data type and format\n","    data_type, format_string = sql_type_to_tmdl_type(sql_type, col_name)\n","    lines.append(f\"\\t\\tdataType: {data_type}\")\n","    \n","    if format_string:\n","        lines.append(f\"\\t\\tformatString: {format_string}\")\n","    \n","    # Lineage tags\n","    col_lineage_tag = deterministic_uuid('column', table_name, col_name)\n","    lines.append(f\"\\t\\tlineageTag: {col_lineage_tag}\")\n","    lines.append(f\"\\t\\tsourceLineageTag: {col_name}\")\n","    \n","    # Summarization\n","    summarize_by = determine_summarization(col_name, sql_type)\n","    lines.append(f\"\\t\\tsummarizeBy: {summarize_by}\")\n","    \n","    # Source column\n","    lines.append(f\"\\t\\tsourceColumn: {col_name}\")\n","    lines.append(\"\")\n","    \n","    # Annotation\n","    lines.append(\"\\t\\tannotation SummarizationSetBy = Automatic\")\n","    lines.append(\"\")\n","    \n","    return \"\\n\".join(lines)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:22.3839033Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:41.418278Z","execution_finish_time":"2026-02-06T10:59:41.7793068Z","parent_msg_id":"688a0f79-bb42-4e0e-8dc7-a6d7dc5fbdc4"}},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7763ed77-ff7e-4250-a223-0541aaa409c8"},{"cell_type":"code","source":["def generate_measure_tmdl(col: Dict[str, Any], table_name: str) -> str:\n","    \"\"\"\n","    Generate TMDL content for a measure based on a measure__ column.\n","\n","    Args:\n","        col: Column metadata dictionary (must have COLUMN_NAME starting with 'measure__')\n","        table_name: Name of the table\n","\n","    Returns:\n","        TMDL string for the measure\n","\n","    Examples:\n","        >>> col = {'COLUMN_NAME': 'measure__total_amount', 'DATA_TYPE': 'decimal'}\n","        >>> tmdl = generate_measure_tmdl(col, 'sales')\n","        >>> 'measure total_amount' in tmdl\n","        True\n","        >>> \"SUM('sales'[measure__total_amount])\" in tmdl\n","        True\n","    \"\"\"\n","    col_name = col['COLUMN_NAME']\n","    measure_name = col_name.replace('measure__', '', 1)\n","\n","    # Always quote measure names for safety and consistency\n","    lines = [f\"\\tmeasure '{measure_name}'\"]\n","\n","    # DAX expression: SUM of the column\n","    # In DAX, column references are always in brackets [column]\n","    lines.append(f\"\\t\\texpression: SUM('{table_name}'[{col_name}])\")\n","\n","    # Format string based on data type\n","    sql_type = col['DATA_TYPE']\n","    _, format_string = sql_type_to_tmdl_type(sql_type, col_name)\n","    if format_string:\n","        lines.append(f\"\\t\\tformatString: {format_string}\")\n","\n","    # Lineage tag\n","    measure_lineage_tag = deterministic_uuid('measure', table_name, col_name)\n","    lines.append(f\"\\t\\tlineageTag: {measure_lineage_tag}\")\n","    lines.append(\"\")\n","\n","    return \"\\n\".join(lines)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:22.7159851Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:41.7804651Z","execution_finish_time":"2026-02-06T10:59:42.0727895Z","parent_msg_id":"4e92691b-5f73-4b6b-9ead-04b1ed4c087c"}},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"d2d7d7ad-86e2-4b8c-85b7-0791f5aedd87"},{"cell_type":"code","source":["def generate_table_tmdl(\n","    table_name: str,\n","    columns: List[Dict[str, Any]],\n","    schema: str,\n","    catalog: str,\n","    entity_name: Optional[str] = None\n",") -> str:\n","    \"\"\"\n","    Generate TMDL content for a single table.\n","\n","    Args:\n","        table_name: Logical name of the table in the model\n","        columns: List of column metadata dictionaries\n","        schema: Schema name\n","        catalog: Catalog name\n","        entity_name: Source table name in the lakehouse (defaults to table_name)\n","\n","    Returns:\n","        Complete TMDL string for the table\n","\n","    Examples:\n","        >>> cols = [\n","        ...     {'COLUMN_NAME': 'id', 'DATA_TYPE': 'bigint'},\n","        ...     {'COLUMN_NAME': 'measure__amount', 'DATA_TYPE': 'decimal'}\n","        ... ]\n","        >>> tmdl = generate_table_tmdl('sales', cols, 'star_schema', 'gold')\n","        >>> 'table sales' in tmdl\n","        True\n","        >>> 'measure amount' in tmdl\n","        True\n","        >>> 'partition sales = entity' in tmdl\n","        True\n","    \"\"\"\n","    if entity_name is None:\n","        entity_name = table_name\n","\n","    # Always quote table names for safety and consistency\n","    table_header = f\"table '{table_name}'\"\n","    lines = [\n","        \"/// Generated by generate_semantic_model.py - Do not edit manually\",\n","        table_header\n","    ]\n","\n","    # Generate unique lineage tags\n","    table_lineage_tag = deterministic_uuid('table', table_name)\n","    lines.append(f\"\tlineageTag: {table_lineage_tag}\")\n","    lines.append(f\"\tsourceLineageTag: [{schema}].[{entity_name}]\")\n","    lines.append(\"\")\n","\n","    # Generate columns\n","    for col in columns:\n","        lines.append(generate_column_tmdl(col, table_name, schema))\n","\n","    # Generate measures for columns prefixed with measure__\n","    measure_columns = [col for col in columns if col['COLUMN_NAME'].startswith('measure__')]\n","    for col in measure_columns:\n","        lines.append(generate_measure_tmdl(col, table_name))\n","\n","    # Partition (for Direct Lake mode)\n","    # Always quote partition names for safety and consistency\n","    partition_header = f\"\tpartition '{table_name}' = entity\"\n","    lines.append(partition_header)\n","    lines.append(\"\t\tmode: directLake\")\n","    lines.append(\"\t\tsource\")\n","    lines.append(f\"\t\t\tentityName: {entity_name}\")\n","    lines.append(f\"\t\t\tschemaName: {schema}\")\n","    lines.append(f\"\t\t\texpressionSource: 'DirectLake - {catalog}'\")\n","\n","    # Annotations\n","    lines.append(\"\")\n","    lines.append(\"\tannotation PBI_ResultMetrics = []\")\n","\n","    return \"\\n\".join(lines) + \"\\n\\n\"\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:23.180687Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:42.0739389Z","execution_finish_time":"2026-02-06T10:59:42.3684671Z","parent_msg_id":"81e654d5-9b5c-47be-b697-a59459472e36"}},"metadata":{}}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"07525b14-1a15-4116-8d51-1172233e10bc"},{"cell_type":"code","source":["def generate_relationships_tmdl(\n","    relationships: List[Dict[str, str]],\n","    manual_relationships: Optional[str] = None,\n","    assume_referential_integrity: bool = False\n",") -> str:\n","    \"\"\"\n","    Generate TMDL content for relationships.\n","\n","    Args:\n","        relationships: List of relationship dictionaries\n","        manual_relationships: Optional string of manually maintained relationships\n","        assume_referential_integrity: Whether to add relyOnReferentialIntegrity (default: False)\n","\n","    Returns:\n","        TMDL string for all relationships\n","\n","    Examples:\n","        >>> rels = [{\n","        ...     'id': '123e4567-e89b-12d3-a456-426614174000',\n","        ...     'from_table': '_events',\n","        ...     'from_column': '_uid__customers',\n","        ...     'to_table': 'customers',\n","        ...     'to_column': '_uid__customers'\n","        ... }]\n","        >>> tmdl = generate_relationships_tmdl(rels)\n","        >>> 'relationship 123e4567-e89b-12d3-a456-426614174000' in tmdl\n","        True\n","        >>> 'fromColumn: _events._uid__customers' in tmdl\n","        True\n","    \"\"\"\n","    lines = []\n","\n","    for rel in relationships:\n","        lines.append(f\"relationship {rel['id']}\")\n","\n","        # Add isActive if specified and false (default is true, so only emit when false)\n","        if 'is_active' in rel and not rel['is_active']:\n","            lines.append(\"\\tisActive: false\")\n","\n","        if assume_referential_integrity:\n","            lines.append(\"\\trelyOnReferentialIntegrity\")\n","        # Always quote table names, column names are not quoted after the dot\n","        # Format: 'Table'.column\n","        from_table_escaped = rel['from_table'].replace(\"'\", \"''\")\n","        to_table_escaped = rel['to_table'].replace(\"'\", \"''\")\n","        from_col = f\"'{from_table_escaped}'.{rel['from_column']}\"\n","        to_col = f\"'{to_table_escaped}'.{rel['to_column']}\"\n","        lines.append(f\"\\tfromColumn: {from_col}\")\n","        lines.append(f\"\\ttoColumn: {to_col}\")\n","        lines.append(\"\")\n","\n","    # Add any preserved manual relationships\n","    if manual_relationships:\n","        lines.append(manual_relationships.rstrip())\n","\n","    # Ensure we don't have trailing empty lines, but do have one final blank line\n","    content = \"\\n\".join(lines).rstrip()\n","    return content + \"\\n\\n\" if content else \"\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:23.6661192Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:42.3696522Z","execution_finish_time":"2026-02-06T10:59:42.6545455Z","parent_msg_id":"20fa06fb-36e9-4f23-a8e9-50ebccaea6ba"}},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"2193d94f-51ab-4a2a-8931-912bc951fe1e"},{"cell_type":"code","source":["def generate_model_tmdl(table_names: List[str], catalog: str, preserved_tables: Optional[List[str]] = None) -> str:\n","    \"\"\"\n","    Generate model.tmdl content.\n","    \n","    Args:\n","        table_names: List of table names\n","        catalog: Catalog name\n","        preserved_tables: List of preserved table names to include\n","    \n","    Returns:\n","        TMDL string for the model\n","        \n","    Examples:\n","        >>> tmdl = generate_model_tmdl(['customers', 'orders'], 'gold')\n","        >>> 'model Model' in tmdl\n","        True\n","        >>> 'ref table customers' in tmdl\n","        True\n","        >>> 'ref table orders' in tmdl\n","        True\n","    \"\"\"\n","    lines = [\n","        \"model Model\",\n","        \"\\tculture: en-US\",\n","        \"\\tdefaultPowerBIDataSourceVersion: powerBI_V3\",\n","        \"\\tdiscourageImplicitMeasures\",\n","        \"\\tsourceQueryCulture: sv-SE\",\n","        \"\\tdataAccessOptions\",\n","        \"\\t\\tlegacyRedirects\",\n","        \"\\t\\treturnErrorValuesAsNull\",\n","        \"\",\n","        f'annotation PBI_QueryOrder = [\"DirectLake - {catalog}\"]',\n","        \"\",\n","        \"annotation __PBI_TimeIntelligenceEnabled = 1\",\n","        \"\",\n","        'annotation PBI_ProTooling = [\"RemoteModeling\",\"DirectLakeOnOneLakeCreatedInDesktop\",\"DirectLakeOnOneLakeInWeb\",\"WebModelingEdit\",\"TMDLView_Desktop\",\"CalcGroup\"]',\n","        \"\"\n","    ]\n","    \n","    # Add generated tables (sorted) - these are all tables NOT in preserved_tables\n","    # Always quote table names for safety and consistency\n","    generated_tables = sorted([t for t in table_names if not preserved_tables or t not in preserved_tables])\n","    for table in generated_tables:\n","        lines.append(f\"ref table '{table}'\")\n","\n","    # Add preserved/manual tables at the end (in their original order, not sorted)\n","    if preserved_tables:\n","        lines.append(\"\")  # Blank line before manual section\n","        for table in preserved_tables:\n","            lines.append(f\"ref table '{table}'\")\n","    \n","    return \"\\n\".join(lines) + \"\\n\\n\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:24.0659994Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:42.6555763Z","execution_finish_time":"2026-02-06T10:59:42.9387708Z","parent_msg_id":"212de699-5634-4567-99a9-ee9986dc189a"}},"metadata":{}}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"0c6b7150-4100-410c-a17c-bbd08dae619f"},{"cell_type":"code","source":["def generate_database_tmdl() -> str:\n","    \"\"\"\n","    Generate database.tmdl content.\n","    \n","    Returns:\n","        TMDL string for the database\n","        \n","    Examples:\n","        >>> tmdl = generate_database_tmdl()\n","        >>> 'database' in tmdl\n","        True\n","        >>> 'compatibilityLevel: 1604' in tmdl\n","        True\n","    \"\"\"\n","    return \"database\\n\\tcompatibilityLevel: 1604\\n\\n\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:24.3971248Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:42.939917Z","execution_finish_time":"2026-02-06T10:59:43.2466959Z","parent_msg_id":"8cfc9184-458a-4c8a-8b0f-682406c719e3"}},"metadata":{}}],"execution_count":14,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"2d499815-d8a8-43fd-924c-1743fca2f435"},{"cell_type":"code","source":["def generate_expressions_tmdl(\n","    catalog: str,\n","    schema: str,\n","    direct_lake_url: str,\n","    preserved_annotations: Optional[str] = None\n",") -> str:\n","    \"\"\"\n","    Generate expressions.tmdl content with DirectLake expression using OneLake.\n","    \n","    Args:\n","        catalog: Catalog name\n","        schema: Schema name\n","        direct_lake_url: Direct Lake URL (e.g., \"https://onelake.dfs.fabric.microsoft.com/workspace-guid/lakehouse-guid\")\n","        preserved_annotations: Optional additional annotations to preserve (e.g., PBI_RemovedChildren)\n","    \n","    Returns:\n","        TMDL string for expressions\n","        \n","    Examples:\n","        >>> tmdl = generate_expressions_tmdl('gold', 'star_schema', 'https://onelake.dfs.fabric.microsoft.com/workspace/lakehouse')\n","        >>> \"expression 'DirectLake - gold'\" in tmdl\n","        True\n","        >>> 'AzureStorage.DataLake' in tmdl\n","        True\n","    \"\"\"\n","    lineage_tag = deterministic_uuid('expression', catalog)\n","    \n","    additional_annotations = f\"\\n\\n{preserved_annotations}\" if preserved_annotations else \"\"\n","    \n","    return f\"\"\"expression 'DirectLake - {catalog}' =\n","\\t\\tlet\n","\\t\\t    Källa = AzureStorage.DataLake(\"{direct_lake_url}\", [HierarchicalNavigation=true])\n","\\t\\tin\n","\\t\\t    Källa\n","\\tlineageTag: {lineage_tag}\n","\n","\\tannotation PBI_IncludeFutureArtifacts = False{additional_annotations}\n","\n","\"\"\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:24.6814648Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:43.2477171Z","execution_finish_time":"2026-02-06T10:59:43.5279128Z","parent_msg_id":"d515be95-1fc1-48a7-bb9d-d9a3b4a6adfa"}},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"e0655dac-593e-4789-b09d-0f3b958b50f7"},{"cell_type":"code","source":["def generate_definition_pbism() -> str:\n","    \"\"\"\n","    Generate definition.pbism content.\n","    \n","    Returns:\n","        JSON string for definition.pbism\n","        \n","    Examples:\n","        >>> pbism = generate_definition_pbism()\n","        >>> '\"version\": \"4.2\"' in pbism\n","        True\n","        >>> '\"$schema\"' in pbism\n","        True\n","    \"\"\"\n","    return \"\"\"{\n","  \"$schema\": \"https://developer.microsoft.com/json-schemas/fabric/item/semanticModel/definitionProperties/1.0.0/schema.json\",\n","  \"version\": \"4.2\",\n","  \"settings\": {}\n","}\"\"\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:24.923463Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:43.529098Z","execution_finish_time":"2026-02-06T10:59:43.8468927Z","parent_msg_id":"f025fe36-8d0b-46e7-b322-b3ab7bac34c5"}},"metadata":{}}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"48f5f187-a286-44b8-a9fa-d8e4eee8480e"},{"cell_type":"code","source":["def generate_platform_file(model_name: str) -> str:\n","    \"\"\"\n","    Generate .platform file content.\n","    \n","    Args:\n","        model_name: Name of the semantic model\n","    \n","    Returns:\n","        JSON string for .platform file\n","        \n","    Examples:\n","        >>> platform = generate_platform_file('Test Model')\n","        >>> '\"displayName\": \"Test Model\"' in platform\n","        True\n","        >>> '\"type\": \"SemanticModel\"' in platform\n","        True\n","    \"\"\"\n","    logical_id = deterministic_uuid('platform', model_name)\n","    return f\"\"\"{{\n","  \"$schema\": \"https://developer.microsoft.com/json-schemas/fabric/gitIntegration/platformProperties/2.0.0/schema.json\",\n","  \"metadata\": {{\n","    \"type\": \"SemanticModel\",\n","    \"displayName\": \"{model_name}\"\n","  }},\n","  \"config\": {{\n","    \"version\": \"2.0\",\n","    \"logicalId\": \"{logical_id}\"\n","  }}\n","}}\"\"\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:25.1554754Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:43.8480407Z","execution_finish_time":"2026-02-06T10:59:44.1465154Z","parent_msg_id":"01766b9b-26ed-498e-b656-1dccc594ec8a"}},"metadata":{}}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7d1a97c5-2632-48e0-84ee-975702de78e0"},{"cell_type":"code","source":["# Project root for resolving output paths\n","project_root = Path.cwd()\n","\n","def get_output_directory(\n","    model_name: str,\n","    output_dir: Optional[str] = None,\n","    script_dir: Optional[Path] = None\n",") -> Tuple[Path, List[str], Optional[str], Optional[str]]:\n","    \"\"\"\n","    Determine the output directory for the semantic model, cleaning generated files while preserving manual content.\n","\n","    Uses watermarks to automatically detect which files are generated vs manually maintained.\n","\n","    Args:\n","        model_name: Name of the semantic model\n","        output_dir: Optional output directory path (relative or absolute)\n","        script_dir: Optional script directory (defaults to current working directory)\n","\n","    Returns:\n","        Tuple of (Path, preserved table names, manual relationships, preserved expr annotations)\n","    \"\"\"\n","    if script_dir is None:\n","        script_dir = Path.cwd()\n","\n","    if output_dir:\n","        if not Path(output_dir).is_absolute():\n","            result_path = script_dir / output_dir / f\"{model_name}.SemanticModel\"\n","        else:\n","            result_path = Path(output_dir) / f\"{model_name}.SemanticModel\"\n","    else:\n","        result_path = script_dir / \"builtin\" / f\"{model_name}.SemanticModel\"\n","\n","    # If directory exists, clean generated files but preserve manual content\n","    preserved_table_names = []\n","    preserved_relationships = None\n","    preserved_expr_annotations = None\n","    watermark = \"/// Generated by generate_semantic_model.py\"\n","\n","    if result_path.exists():\n","        tables_dir = result_path / \"definition\" / \"tables\"\n","        generated_table_names = set()\n","\n","        if tables_dir.exists():\n","            # Auto-detect and preserve non-watermarked tables\n","            for table_file in tables_dir.iterdir():\n","                if table_file.suffix == \".tmdl\":\n","                    content = table_file.read_text(encoding=\"utf-8\")\n","                    if content.startswith(watermark):\n","                        # Generated file - track name and delete it\n","                        generated_table_names.add(table_file.stem)\n","                        table_file.unlink()\n","                    else:\n","                        # Manual file - preserve it\n","                        preserved_table_names.append(table_file.stem)\n","\n","            import re\n","\n","            # Extract manual relationships by parsing existing file\n","            rel_path = result_path / \"definition\" / \"relationships.tmdl\"\n","            if rel_path.exists():\n","                existing_content = rel_path.read_text(encoding=\"utf-8\")\n","\n","                # Parse all relationships from the file\n","                relationship_pattern = r'relationship\\s+([\\w\\-]+)\\s+.*?fromColumn:\\s+(\\w+)\\..*?toColumn:\\s+(\\w+)\\.'\n","                matches = re.findall(relationship_pattern, existing_content, re.DOTALL)\n","\n","                manual_rels = []\n","                for match in matches:\n","                    rel_id, from_table, to_table = match\n","                    # If either table is NOT in generated set, this is a manual relationship\n","                    if from_table not in generated_table_names or to_table not in generated_table_names:\n","                        # Extract this relationship block\n","                        rel_block_pattern = rf'relationship\\s+{re.escape(rel_id)}.*?(?=relationship\\s+[\\w\\-]+|///|$)'\n","                        rel_match = re.search(rel_block_pattern, existing_content, re.DOTALL)\n","                        if rel_match:\n","                            manual_rels.append(rel_match.group(0).strip())\n","\n","                if manual_rels:\n","                    preserved_relationships = \"\\n\\n\".join(manual_rels)\n","\n","            # Extract additional annotations from expressions.tmdl (e.g., PBI_RemovedChildren)\n","            expr_path = result_path / \"definition\" / \"expressions.tmdl\"\n","            if expr_path.exists():\n","                expr_content = expr_path.read_text(encoding=\"utf-8\")\n","                # Find all annotation lines after PBI_IncludeFutureArtifacts\n","                include_future_match = re.search(r'annotation\\s+PBI_IncludeFutureArtifacts\\s*=\\s*\\w+', expr_content)\n","                if include_future_match:\n","                    after_include_future = expr_content[include_future_match.end():]\n","                    # Extract remaining annotations (anything starting with whitespace+annotation)\n","                    additional_annotations = []\n","                    # Match lines that start with tabs/spaces followed by 'annotation'\n","                    annotation_pattern = r'([ \\t]+annotation\\s+\\S+\\s*=\\s*[^\\n]+)'\n","                    for match in re.finditer(annotation_pattern, after_include_future):\n","                        annotation_text = match.group(1)\n","                        if annotation_text.strip():\n","                            additional_annotations.append(annotation_text)\n","                    if additional_annotations:\n","                        preserved_expr_annotations = \"\\n\\n\".join(additional_annotations)\n","                        print(f\"Preserved {len(additional_annotations)} expression annotation(s)\")\n","\n","            if preserved_table_names:\n","                print(f\"Preserved {len(preserved_table_names)} manually maintained table(s): {', '.join(preserved_table_names)}\")\n","\n","    # Ensure directory structure exists\n","    result_path.mkdir(parents=True, exist_ok=True)\n","    (result_path / \"definition\" / \"tables\").mkdir(parents=True, exist_ok=True)\n","\n","    # Return preserved table names, relationships, and expression annotations\n","    return result_path, preserved_table_names, preserved_relationships, preserved_expr_annotations\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:25.3267385Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:44.1475663Z","execution_finish_time":"2026-02-06T10:59:44.435393Z","parent_msg_id":"1ef45517-3600-4511-9f3f-76dbaa41eca3"}},"metadata":{}}],"execution_count":18,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"83db16c5"},{"cell_type":"code","source":["def save_semantic_model_files(\n","    output_dir: Path,\n","    tables_metadata: Dict[str, List[Dict[str, Any]]],\n","    relationships: List[Dict[str, str]],\n","    catalog: str,\n","    model_name: str,\n","    direct_lake_url: str,\n","    table_schemas: Dict[str, str],\n","    table_entities: Dict[str, str],\n","    preserved_tables: Optional[List[str]] = None,\n","    preserved_relationships: Optional[str] = None,\n","    preserved_expr_annotations: Optional[str] = None,\n","    assume_referential_integrity: bool = False\n",") -> None:\n","    \"\"\"\n","    Save all generated TMDL files to disk.\n","\n","    Args:\n","        output_dir: Output directory path\n","        tables_metadata: Dictionary mapping table names to column metadata\n","        relationships: List of relationship dictionaries\n","        catalog: Catalog name\n","        model_name: Model name\n","        direct_lake_url: Direct Lake URL\n","        table_schemas: Mapping of table_name -> schema\n","        table_entities: Mapping of table_name -> source entity/table name\n","        preserved_expr_annotations: Optional preserved expression annotations (e.g., PBI_RemovedChildren)\n","        assume_referential_integrity: Whether to add relyOnReferentialIntegrity to relationships (default: False)\n","    \"\"\"\n","    def _display_path(path: Path) -> str:\n","        try:\n","            return path.resolve().relative_to(project_root.resolve()).as_posix()\n","        except Exception:\n","            return str(path.resolve())\n","\n","    # Resolve and normalize the path to remove '..' segments\n","    print(f\"\\nGenerating semantic model files in {_display_path(output_dir)}...\")\n","\n","    # Create directory structure\n","    definition_dir = output_dir / \"definition\"\n","    tables_dir = definition_dir / \"tables\"\n","    tables_dir.mkdir(parents=True, exist_ok=True)\n","\n","    # Generate and save definition.pbism\n","    pbism_path = output_dir / \"definition.pbism\"\n","    pbism_path.write_text(generate_definition_pbism(), encoding=\"utf-8\")\n","    print(f\"  Created {_display_path(pbism_path)}\")\n","\n","    # Generate and save .platform\n","    platform_path = output_dir / \".platform\"\n","    platform_path.write_text(generate_platform_file(model_name), encoding=\"utf-8\")\n","    print(f\"  Created {_display_path(platform_path)}\")\n","\n","    # Generate and save database.tmdl\n","    db_path = definition_dir / \"database.tmdl\"\n","    db_path.write_text(generate_database_tmdl(), encoding=\"utf-8\")\n","    print(f\"  Created {_display_path(db_path)}\")\n","\n","    # Generate and save model.tmdl\n","    model_path = definition_dir / \"model.tmdl\"\n","    table_names = list(tables_metadata.keys())\n","    model_path.write_text(generate_model_tmdl(table_names, catalog, preserved_tables), encoding=\"utf-8\")\n","    print(f\"  Created {_display_path(model_path)}\")\n","\n","    # Generate and save expressions.tmdl\n","    expr_path = definition_dir / \"expressions.tmdl\"\n","    expr_path.write_text(generate_expressions_tmdl(catalog, None, direct_lake_url, preserved_expr_annotations), encoding=\"utf-8\")\n","    print(f\"  Created {_display_path(expr_path)}\")\n","\n","    # Generate and save relationships.tmdl (with preserved manual relationships)\n","    rel_path = definition_dir / \"relationships.tmdl\"\n","    if preserved_relationships:\n","        print(f\"  Preserving {len(preserved_relationships.splitlines())} line(s) of manual relationships\")\n","\n","    rel_path.write_text(generate_relationships_tmdl(relationships, preserved_relationships, assume_referential_integrity), encoding=\"utf-8\")\n","    print(f\"  Created {_display_path(rel_path)}\")\n","\n","    # Generate and save table TMDL files\n","    total_measures = 0\n","    for table_name, columns in tables_metadata.items():\n","        table_path = tables_dir / f\"{table_name}.tmdl\"\n","        schema = table_schemas.get(table_name)\n","        entity_name = table_entities.get(table_name, table_name)\n","        tmdl_content = generate_table_tmdl(table_name, columns, schema, catalog, entity_name=entity_name)\n","        table_path.write_text(tmdl_content, encoding=\"utf-8\")\n","        # Count measures in this table\n","        measure_count = sum(1 for col in columns if col['COLUMN_NAME'].startswith('measure__'))\n","        total_measures += measure_count\n","\n","    print(\"\\n✓ Semantic model generated successfully!\")\n","    print(f\"  Total tables: {len(tables_metadata)}\")\n","    print(f\"  Total relationships: {len(relationships)}\")\n","    print(f\"  Total measures: {total_measures}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:25.4966831Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:44.43645Z","execution_finish_time":"2026-02-06T10:59:44.7845675Z","parent_msg_id":"10dc4450-e439-4252-9d3b-3799ea8d15fb"}},"metadata":{}}],"execution_count":19,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"6fb22ae0-1cef-4fe9-bbdc-3c6fb3d2485d"},{"cell_type":"code","source":["def build_tables_metadata_from_df(\n","    df,\n","    catalog: str,\n","    schemas\n",") -> Tuple[Dict[str, List[Dict[str, Any]]], Dict[str, str], Dict[str, str]]:\n","    \"\"\"\n","    Build table metadata from INFORMATION_SCHEMA.COLUMNS DataFrame.\n","\n","    Returns:\n","        tables_metadata: table_id -> list of column dicts\n","        table_schemas: table_id -> schema name\n","        table_entities: table_id -> source table name\n","    \"\"\"\n","    if isinstance(schemas, str):\n","        schemas = [schemas]\n","\n","    schemas_lower = [s.lower() for s in schemas]\n","\n","    # Filter to target catalog/schemas\n","    df_filtered = df[\n","        (df[\"TABLE_CATALOG\"].str.lower() == catalog.lower()) &\n","        (df[\"TABLE_SCHEMA\"].str.lower().isin(schemas_lower))\n","    ].copy()\n","\n","    # Determine if table name collisions exist across schemas\n","    name_counts = df_filtered.groupby(\"TABLE_NAME\")[\"TABLE_SCHEMA\"].nunique()\n","    has_collisions = any(name_counts > 1)\n","    multi_schema = len(schemas) > 1\n","\n","    # Sort by schema/table + ordinal position to preserve column order\n","    df_filtered.sort_values(\n","        [\"TABLE_SCHEMA\", \"TABLE_NAME\", \"ORDINAL_POSITION\"],\n","        inplace=True\n","    )\n","\n","    tables_metadata: Dict[str, List[Dict[str, Any]]] = {}\n","    table_schemas: Dict[str, str] = {}\n","    table_entities: Dict[str, str] = {}\n","\n","    for _, row in df_filtered.iterrows():\n","        schema = row[\"TABLE_SCHEMA\"]\n","        table_name = row[\"TABLE_NAME\"]\n","        if multi_schema or has_collisions:\n","            table_id = f\"{schema}.{table_name}\"\n","        else:\n","            table_id = table_name\n","\n","        tables_metadata.setdefault(table_id, []).append({\n","            \"COLUMN_NAME\": row[\"COLUMN_NAME\"],\n","            \"DATA_TYPE\": row[\"DATA_TYPE\"],\n","            \"IS_NULLABLE\": row.get(\"IS_NULLABLE\", \"YES\"),\n","            \"CHARACTER_MAXIMUM_LENGTH\": row.get(\"CHARACTER_MAXIMUM_LENGTH\"),\n","            \"NUMERIC_PRECISION\": row.get(\"NUMERIC_PRECISION\"),\n","            \"NUMERIC_SCALE\": row.get(\"NUMERIC_SCALE\"),\n","            \"ORDINAL_POSITION\": row.get(\"ORDINAL_POSITION\"),\n","        })\n","        table_schemas[table_id] = schema\n","        table_entities[table_id] = table_name\n","\n","    return tables_metadata, table_schemas, table_entities\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:25.6713607Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:44.7857531Z","execution_finish_time":"2026-02-06T10:59:45.1221764Z","parent_msg_id":"632e6fa8-e884-444c-a239-28a4a8a2fa7d"}},"metadata":{}}],"execution_count":20,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"ae65575c-7afb-47a1-b0f9-4937811c3ea1"},{"cell_type":"code","source":["def classify_tables_by_keys(tables_metadata: Dict[str, List[Dict[str, Any]]], key_prefixes) -> Tuple[List[str], List[str], List[str]]:\n","    \"\"\"Classify tables into dims, facts, and others based on key column count.\"\"\"\n","    if key_prefixes is None:\n","        key_prefixes = ['_hk__', '_wk__']\n","    elif isinstance(key_prefixes, str):\n","        key_prefixes = [key_prefixes]\n","\n","    dims = []\n","    facts = []\n","    others = []\n","\n","    for table_name, columns in tables_metadata.items():\n","        key_cols = [\n","            col for col in columns\n","            if any(col['COLUMN_NAME'].startswith(prefix) for prefix in key_prefixes)\n","        ]\n","\n","        if len(key_cols) == 1:\n","            dims.append(table_name)\n","        elif len(key_cols) > 1:\n","            facts.append(table_name)\n","        else:\n","            others.append(table_name)\n","\n","    return sorted(dims), sorted(facts), sorted(others)\n","\n","\n","def generate_diagram_layout_stub(\n","    tables_metadata: Dict[str, List[Dict[str, Any]]],\n","    key_prefixes,\n","    table_width: int = 220,\n","    table_height: int = 140,\n","    x_gap: int = 40,\n","    y_gap: int = 40\n",") -> Dict[str, Any]:\n","    \"\"\"Generate a simple diagram layout JSON with dims horizontal and facts vertical.\"\"\"\n","    dims, facts, others = classify_tables_by_keys(tables_metadata, key_prefixes)\n","\n","    layout = {\n","        \"version\": 1,\n","        \"tables\": []\n","    }\n","\n","    # Place dimensions horizontally (row)\n","    x = 0\n","    y = 0\n","    for name in dims:\n","        layout[\"tables\"].append({\n","            \"name\": name,\n","            \"x\": x,\n","            \"y\": y,\n","            \"width\": table_width,\n","            \"height\": table_height\n","        })\n","        x += table_width + x_gap\n","\n","    # Place facts vertically (column)\n","    x = max(x, table_width + x_gap) + (table_width + x_gap)\n","    y = 0\n","    for name in facts:\n","        layout[\"tables\"].append({\n","            \"name\": name,\n","            \"x\": x,\n","            \"y\": y,\n","            \"width\": table_width,\n","            \"height\": table_height\n","        })\n","        y += table_height + y_gap\n","\n","    # Place others in a second row under dims\n","    x = 0\n","    y = max(y, table_height + y_gap) + (table_height + y_gap)\n","    for name in others:\n","        layout[\"tables\"].append({\n","            \"name\": name,\n","            \"x\": x,\n","            \"y\": y,\n","            \"width\": table_width,\n","            \"height\": table_height\n","        })\n","        x += table_width + x_gap\n","\n","    return layout\n","\n","\n","def write_diagram_layout_json(\n","    output_dir: Path,\n","    tables_metadata: Dict[str, List[Dict[str, Any]]],\n","    key_prefixes\n",") -> Path:\n","    \"\"\"Write a best-effort diagramLayout.json next to the semantic model definition.\"\"\"\n","    layout = generate_diagram_layout_stub(tables_metadata, key_prefixes)\n","    path = output_dir / \"diagramLayout.json\"\n","    path.write_text(json.dumps(layout, indent=2), encoding=\"utf-8\")\n","    return path\n","\n","\n","def build_definition_payload(model_dir: Path) -> Dict[str, Any]:\n","    \"\"\"Build Fabric REST API definition payload from a SemanticModel folder.\"\"\"\n","    parts = []\n","    for path in sorted(model_dir.rglob('*')):\n","        if not path.is_file():\n","            continue\n","        if path.name == \"definition_payload.json\":\n","            continue\n","        rel_path = path.relative_to(model_dir).as_posix()\n","        payload = base64.b64encode(path.read_bytes()).decode('utf-8')\n","        parts.append({\n","            \"path\": rel_path,\n","            \"payload\": payload,\n","            \"payloadType\": \"InlineBase64\"\n","        })\n","\n","    return {\n","        \"parts\": parts\n","    }\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:25.8358852Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:45.1234083Z","execution_finish_time":"2026-02-06T10:59:45.4040248Z","parent_msg_id":"72b2f3d4-0959-4b11-891a-4f50a8832bf3"}},"metadata":{}}],"execution_count":21,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"99ee53a7"},{"cell_type":"code","source":["def create_semantic_model_in_fabric(\n","    workspace_id: str,\n","    display_name: str,\n","    definition: Dict[str, Any],\n","    description: Optional[str] = None,\n","    folder_id: Optional[str] = None,\n","    poll_interval_seconds: int = 5\n",") -> Dict[str, Any]:\n","    \"\"\"Create a semantic model via Fabric REST API and return the result.\"\"\"\n","    token = notebookutils.credentials.getToken(\"https://api.fabric.microsoft.com\")\n","    headers = {\n","        \"Authorization\": f\"Bearer {token}\",\n","        \"Content-Type\": \"application/json\"\n","    }\n","\n","    payload = {\n","        \"displayName\": display_name,\n","        \"definition\": definition\n","    }\n","    if description:\n","        payload[\"description\"] = description\n","    if folder_id:\n","        payload[\"folderId\"] = folder_id\n","\n","    url = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/semanticModels\"\n","    response = requests.post(url, headers=headers, json=payload)\n","\n","    if response.status_code == 201:\n","        return response.json()\n","\n","    if response.status_code == 202:\n","        location = response.headers.get(\"Location\")\n","        if not location:\n","            raise RuntimeError(\"202 Accepted without Location header\")\n","\n","        # Poll LRO\n","        while True:\n","            time.sleep(poll_interval_seconds)\n","            lro = requests.get(location, headers=headers)\n","            if lro.status_code >= 400:\n","                raise RuntimeError(f\"LRO failed: {lro.status_code} {lro.text}\")\n","            data = lro.json() if lro.content else {}\n","            status = data.get(\"status\") or data.get(\"provisioningState\")\n","            if status in (\"Succeeded\", \"Failed\", \"Canceled\", \"Cancelled\"):\n","                return data\n","\n","    # Other errors\n","    raise RuntimeError(f\"Create failed: {response.status_code} {response.text}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:25.9853186Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:45.4050755Z","execution_finish_time":"2026-02-06T10:59:45.6987742Z","parent_msg_id":"1536032e-1846-4bde-bf78-00130369e97d"}},"metadata":{}}],"execution_count":22,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3f22aebb"},{"cell_type":"code","source":["def generate_semantic_model(\n","    metadata_df,\n","    catalog: str,\n","    schemas,\n","    model_name: str,\n","    direct_lake_url: str,\n","    output_dir: Optional[str] = None,\n","    key_prefixes: Union[str, List[str]] = None,\n","    exact_match_prefixes: Union[str, List[str]] = None,\n","    assume_referential_integrity: bool = False\n",") -> None:\n","    \"\"\"\n","    Main workflow function to generate a complete semantic model.\n","\n","    Automatically preserves manually maintained content (non-watermarked files).\n","\n","    Relationship detection:\n","    - Dimension: Tables with exactly 1 key column (their primary key)\n","    - Fact: Tables with >1 key columns (their PK + foreign keys to dimensions)\n","    - Creates 1:* relationships from dimension to fact\n","\n","    Args:\n","        metadata_df: DataFrame holding INFORMATION_SCHEMA.COLUMNS\n","        catalog: Database catalog name (e.g., \"gold\")\n","        schemas: Schema name or list of schemas (e.g., \"Dim\" or [\"Dim\", \"Fact\"])\n","        model_name: Name for the semantic model\n","        direct_lake_url: Direct Lake URL for OneLake connection\n","        output_dir: Optional output directory path\n","        key_prefixes: Column prefix(es) to identify relationship keys. Can be a string or list of strings (default: ['_hk__', '_wk__'])\n","        exact_match_prefixes: Column prefix(es) that should use exact matching only, not role-playing pattern (default: ['_wk__ref__'])\n","        assume_referential_integrity: Whether to add relyOnReferentialIntegrity to relationships (default: False)\n","    \"\"\"\n","    if key_prefixes is None:\n","        key_prefixes = ['_hk__', '_wk__']\n","    elif isinstance(key_prefixes, str):\n","        key_prefixes = [key_prefixes]\n","\n","    if exact_match_prefixes is None:\n","        exact_match_prefixes = ['_wk__ref__']\n","    elif isinstance(exact_match_prefixes, str):\n","        exact_match_prefixes = [exact_match_prefixes]\n","\n","    # Get output directory (auto-preserves non-watermarked content)\n","    script_dir = Path.cwd()\n","    output_path, preserved_table_names, preserved_relationships, preserved_expr_annotations = get_output_directory(model_name, output_dir, script_dir)\n","\n","    # Build column metadata from information schema dataframe\n","    print(f\"\\nBuilding tables from {catalog} information schema...\")\n","    tables_metadata, table_schemas, table_entities = build_tables_metadata_from_df(metadata_df, catalog, schemas)\n","    tables = list(tables_metadata.keys())\n","    print(f\"Found {len(tables)} tables from information schema\")\n","\n","    # Identify relationships (1 key col = dim, >1 = fact)\n","    prefixes_str = ', '.join(f\"'{p}'\" for p in key_prefixes)\n","    print(f\"\\nIdentifying relationships (key prefixes: {prefixes_str})...\")\n","    relationships, tables_without_relationships = identify_relationships(\n","        tables_metadata,\n","        key_prefixes=key_prefixes,\n","        exact_match_prefixes=exact_match_prefixes\n","    )\n","    print(f\"Found {len(relationships)} relationships\")\n","\n","    # Print tables with no relationships\n","    if tables_without_relationships:\n","        print(f\"\\nWarning: {len(tables_without_relationships)} table(s) have no relationships detected:\")\n","        for table in tables_without_relationships:\n","            print(f\"  - {table}\")\n","    else:\n","        print(\"\\nAll tables have relationships.\")\n","\n","    # Save all files\n","    # Write diagram layout (best-effort)\n","    write_diagram_layout_json(output_path, tables_metadata, key_prefixes)\n","    save_semantic_model_files(\n","        output_path,\n","        tables_metadata,\n","        relationships,\n","        catalog,\n","        model_name,\n","        direct_lake_url,\n","        table_schemas,\n","        table_entities,\n","        preserved_table_names,\n","        preserved_relationships,\n","        preserved_expr_annotations,\n","        assume_referential_integrity\n","    )\n","\n","    return output_path\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:26.245947Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:45.6999784Z","execution_finish_time":"2026-02-06T10:59:46.0132684Z","parent_msg_id":"382ea05f-b9fa-41d0-aa9c-af9b2472e3ac"}},"metadata":{}}],"execution_count":23,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"e3b69d64-f957-40e4-bc9b-b13fda8a7809"},{"cell_type":"markdown","source":["## Execute"],"metadata":{},"id":"fdf78ecc"},{"cell_type":"code","source":["import sempy.fabric as sf\n","\n","workspace_id = \"e0573fbd-c1f4-4993-afa3-320620c17110\"\n","warehouse_id = \"9a3d14f5-8ce7-49e4-b79d-3ab8b834e16e\"\n","model_name = \"One Model To Rule Them All (Chris)\"\n","direct_lake_url = f\"https://onelake.dfs.fabric.microsoft.com/{workspace_id}/{warehouse_id}\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:26.5218378Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:46.0144555Z","execution_finish_time":"2026-02-06T10:59:47.1995752Z","parent_msg_id":"10be5480-9e12-41c8-b37f-673664e4417b"}},"metadata":{}}],"execution_count":24,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"344d5559"},{"cell_type":"code","source":["# Connect to warehouse\n","sql_endpoint = \"5dscrplirguurh56sz3vy633zu-xu7vpyhuygjutl5dgidcbqlrca.datawarehouse.fabric.microsoft.com\"\n","database = \"WH_Gold\"\n","cursor = connect_to_warehouse(sql_endpoint, database)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:26.8023964Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:47.2006418Z","execution_finish_time":"2026-02-06T10:59:49.123456Z","parent_msg_id":"65de68bc-3463-40ef-8de8-69637aa781a2"}},"metadata":{}}],"execution_count":25,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"d5e9815e"},{"cell_type":"code","source":["# Load information schema\n","metadata = load_information_schema(cursor, schemas=[\"Dim\", \"Fact\"])\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T10:59:27.0539878Z","session_start_time":null,"execution_start_time":"2026-02-06T10:59:49.124765Z","execution_finish_time":"2026-02-06T10:59:50.2943398Z","parent_msg_id":"ab48d117-9000-4338-8209-7447a730f2f5"}},"metadata":{}}],"execution_count":26,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"cb68fc61"},{"cell_type":"code","source":["# Run generator\n","model_dir = generate_semantic_model(\n","    metadata,\n","    catalog=database,\n","    schemas=[\"Dim\", \"Fact\"],\n","    model_name=model_name,\n","    key_prefixes=\"ID_\",\n","    direct_lake_url=direct_lake_url,\n","    output_dir=\"./builtin\"\n",")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T11:05:47.8353851Z","session_start_time":null,"execution_start_time":"2026-02-06T11:05:47.8362634Z","execution_finish_time":"2026-02-06T11:05:53.4816552Z","parent_msg_id":"f2ca55db-567c-4c34-991a-5747ef7bbfd7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\nBuilding tables from WH_Gold information schema...\nFound 45 tables from information schema\n\nIdentifying relationships (key prefixes: 'ID_')...\nFound 72 relationships\n\nWarning: 15 table(s) have no relationships detected:\n  - Dim.AttributeTable\n  - Dim.BaseCurrency\n  - Dim.BusinessUnit\n  - Dim.CurrencyExRateLatest\n  - Dim.Date\n  - Dim.Fardigvara\n  - Dim.FinishedGoods\n  - Dim.PL_Link\n  - Dim.ProdCodeForInvPart\n  - Dim.TechnicalSpecificationGroup\n  - Dim.YearMonth\n  - Dim.vBaseCurrency\n  - Dim.vProdCodeForInvPart\n  - Fact.ModuleStatusInterval\n  - Fact.StockBalance\n\nGenerating semantic model files in /synfs/resource/nb_resource/builtin/One Model To Rule Them All (Chris).SemanticModel...\n  Created /synfs/resource/nb_resource/builtin/One Model To Rule Them All (Chris).SemanticModel/definition.pbism\n  Created /synfs/resource/nb_resource/builtin/One Model To Rule Them All (Chris).SemanticModel/.platform\n  Created /synfs/resource/nb_resource/builtin/One Model To Rule Them All (Chris).SemanticModel/definition/database.tmdl\n  Created /synfs/resource/nb_resource/builtin/One Model To Rule Them All (Chris).SemanticModel/definition/model.tmdl\n  Created /synfs/resource/nb_resource/builtin/One Model To Rule Them All (Chris).SemanticModel/definition/expressions.tmdl\n  Created /synfs/resource/nb_resource/builtin/One Model To Rule Them All (Chris).SemanticModel/definition/relationships.tmdl\n\n✓ Semantic model generated successfully!\n  Total tables: 45\n  Total relationships: 72\n  Total measures: 0\n"]}],"execution_count":28,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"4f132c31"},{"cell_type":"code","source":["# Build REST API definition payload\n","definition_payload = build_definition_payload(model_dir)\n","payload_path = model_dir / \"definition_payload.json\"\n","payload_path.write_text(json.dumps(definition_payload, indent=2), encoding=\"utf-8\")\n","print(f\"Wrote {payload_path}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T11:05:48.2325749Z","session_start_time":null,"execution_start_time":"2026-02-06T11:05:53.4827658Z","execution_finish_time":"2026-02-06T11:05:55.5170766Z","parent_msg_id":"6cf48fe5-0c09-47b5-95a5-a16cc30bf903"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Wrote /home/trusted-service-user/work/builtin/One Model To Rule Them All (Chris).SemanticModel/definition_payload.json\n"]}],"execution_count":29,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"0ed2d197"},{"cell_type":"code","source":["# Create semantic model in Fabric\n","description = \"Generated from INFORMATION_SCHEMA\"\n","\n","result = create_semantic_model_in_fabric(\n","    workspace_id=workspace_id,\n","    display_name=model_name,\n","    description=description,\n","    definition=definition_payload\n",")\n","print(result)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"f6e83f05-bf83-486c-a05b-b7aafd081b65","normalized_state":"finished","queued_time":"2026-02-06T11:05:49.0040254Z","session_start_time":null,"execution_start_time":"2026-02-06T11:05:55.5183327Z","execution_finish_time":"2026-02-06T11:06:12.1250769Z","parent_msg_id":"c946c047-d4ee-4771-85bb-af57d2db88fc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'status': 'Succeeded', 'createdTimeUtc': '2026-02-06T11:05:56.1997074', 'lastUpdatedTimeUtc': '2026-02-06T11:06:09.5313677', 'percentComplete': 100, 'error': None}\n"]}],"execution_count":30,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3330834e"}],"metadata":{"kernel_info":{"jupyter_kernel_name":"python3.11","name":"jupyter"},"kernelspec":{"display_name":"Jupyter","name":"jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}